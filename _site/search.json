[
  {
    "objectID": "how-to-contribute.html",
    "href": "how-to-contribute.html",
    "title": "How to Contribute",
    "section": "",
    "text": "We hope R Works will attract other voices from around the R Community, including yourself! We’re always looking for high-quality, original work to demonstrate the power of R. If you would like to contribute R-related topics, news, commentary, or examples, please follow this process to submit a post for consideration."
  },
  {
    "objectID": "how-to-contribute.html#faqs",
    "href": "how-to-contribute.html#faqs",
    "title": "How to Contribute",
    "section": "FAQs",
    "text": "FAQs\n\nCan I cross-post my blog post?\n\nYes, you can cross-post your blog post as long as it is published at the same time as the one on R Works.\n\nDo you edit posts from the past?\n\nOnce published, we only edit posts from the past for typos or broken links."
  },
  {
    "objectID": "how-to-contribute.html#code-of-conduct",
    "href": "how-to-contribute.html#code-of-conduct",
    "title": "How to Contribute",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nR Works is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms."
  },
  {
    "objectID": "how-to-contribute.html#license",
    "href": "how-to-contribute.html#license",
    "title": "How to Contribute",
    "section": "License",
    "text": "License\nUnless otherwise noted, content on R Works is licensed under the CC-BY license."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Works",
    "section": "",
    "text": "Welcome to R Works!\n\n\n\n\n\n\nR Community\n\n\n\nWe hope that the R Works blog informs and inspires R users everywhere.\n\n\n\n\n\n2024-10-29\n\n\n\n\n\n\n\n\n\n\n\n\nSeptember 2024: Top 40 New CRAN Packages\n\n\n\n\n\n\nTop 40\n\n\n\nTwo hundred thirty new packages made it to CRAN in September. Here are my “Top 40” selections in 17 categories.\n\n\n\n\n\n2024-10-29\n\n\nJoseph Rickert\n\n\n\n\n\n\n\n\n\n\n\n\nAugust 2024: Top 40 New CRAN Packages\n\n\n\n\n\n\nTop 40\n\n\n\n“Top 40” is back, broadcasting on the new R Works blog.\n\n\n\n\n\n2024-10-29\n\n\nJoseph Rickert\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/september-2024-top-40-new-cran-packages/index.html",
    "href": "posts/september-2024-top-40-new-cran-packages/index.html",
    "title": "September 2024: Top 40 New CRAN Packages",
    "section": "",
    "text": "Two hundred thirty new packages made it to CRAN in September, many of them were interesting, and selecting only forty made for some difficult decisions. When there a difficult choice, I opted in favor of the sciences. Here are my picks for the Top 40 new packages in fifteen categories: AI, Archaeology, Biology, Computational Methods, Data, Genomics, Linguistics, Machine Learning, Medicine, Networks, Pharma, Physics, Statistics, Utilities, and Visualization.\n\nAI\ngroqR v0.0.1: Provides a suite of functions and RStudio Add-ins leveraging the capabilities of open-source Large Language Models (LLMs) to support R developers. Features include text rewriting, translation, and general query capabilities. Programming-focused functions provide assistance with debugging, translating, commenting, documenting, and unit testing code, as well as suggesting variable and function names. Look here for examples.\n\n\nArchaeology\neratosthenes v0.0.2: Estimates unknown historical or archaeological dates subject to relationships with other dates and absolute constraints, derived as marginal densities from the full joint conditional distribution. Includes rule-based estimation of the production dates of artifact types. See Collins-Elliott (2024) for background and the vignettes on aligning relative sequences and gibbs sampling for archaeology dates.\n\n\nBiology\npcvr v1.0.0: Provides functions to analyse common types of plant phenotyping data and a simplified interface to longitudinal growth modeling and select Bayesian statistics. See Kruschke (2018), Kruschke (2013) and Kruschke (2021) for background on the Bayesian methods. There are four vignettes including Bellwether workflow and Longitudinal Growth Modeling.\n\n\n\n\n\northGS v0.1.5: Provides tools to analyze and infer orthology and paralogy relationships between glutamine synthetase proteins in seed plants. See the vignettes Searching for Orthologous and Unraveling the Hiden Paralogous.\n\n\n\n\n\n\n\nChemistry\nMethodOpt v1.0.0: Implements a GUI to apply an advanced method optimization algorithm to various sampling and analysis instruments. Functions include generating experimental designs, uploading and viewing data, and performing various analyses to determine the optimal method. See Granger & Mannion (2024) for details and the vignette for examples.\nSCFMonitor v0.3.5: Self-Consistent Field(SCF) calculation method is one of the most important steps in the calculation methods of quantum chemistry. See Ehrenreich & Cohen (1959) . This package enables Gaussian quantum chemistry calculation software users to easily read the Gaussian .log files and monitor the SCF convergence and geometry optimization process. Look here for examples.\n\n\n\n\n\n\n\nComputational Methods\nXDNUTS v1.2: Implements Hamiltonian Monte Carlo for both continuous and discontinuous posterior distributions with customisable trajectory length termination criterion. See Nishimura et al. (2020) for the original Discontinuous Hamiltonian Monte Carlo; and Hoffman et al. (2014) and Betancourt (2016) possible Hamiltonian Monte Carlo termination criteria. The vignette offers examples.\n\n\n\n\n\n\n\nData\nclintrialx v0.1.0: Provides functions to fetch clinical trial data from sources like [ClinicalTrials.gov](https://clinicaltrials.gov/} and the Clinical Trials Access to Aggregate Content database that supports pagination and bulk downloads. See the vignette.\n\n\n\n\n\nColOpenData v0.3.0: Provides tools to download and wrangle Colombian socioeconomic, geospatial,population and climate data from DANE at the National Administrative Department of Statistics and IDEAM at the Institute of Hydrology, Meteorology and Environmental Studies. It solves the problem of Colombian data being issued in different web pages and sources by using functions that allow the user to select the desired database and download it without having to do the exhausting acquisition process. There are six vignettes including How to download climate data and Population Projections.\n\n\n\n\n\nmodgo v1.0.1: Provides functions to generate synthetic data from a real dataset using the combination of rank normal inverse transformation with the calculation of correlation matrix and completely artificial data may be generated through the use of Generalized Lambda Distribution and Generalized Poisson Distribution. See the vignette.\n\n\n\n\n\ndtmapi v0.0.2: Provides functions to allow humanitarian community, academia, media, government, and non-governmental organizations to utilize the data collected by the Displacement Tracking Matrix, a unit in the International Organization for Migration. See the vignette to get started.\n\n\nEcology\ndouconca v1.2.1: Implements the two step double constrained correspondence analysis (dc-CA) for analyzing multi-trait multi-environment ecological data described inter Braak et al. (2018). This algorithm combines and extends community or sample and species-level analyses.\n\n\n\n\n\nGeoThinneR v1.1.0: Provides efficient geospatial thinning algorithms to reduce the density of coordinate data while maintaining spatial relationships. Implements K-D Tree and brute-force distance-based thinning, as well as grid-based and precision-based thinning methods. See Elseberg et al. (2012) for background and the vignette for examples.\n\n\n\n\n\n\n\nGenomics\neasybio v1.1.0: Provides a toolkit for single-cell annotation with the CellMarker2.0 database and streamlines biological label assignment in single-cell RNA-seq data and facilitates transcriptomic analysis, including preparation of TCGA and GEO datasets, differential expression analysis and visualization of enrichment analysis results. See Wei Cui (2024) for details and the two vignettes bulk RNAsewuence workflow and Single Cell Annotation for examples.\n\n\n\n\n\nGenoPop v0.9.3: Implements tools for efficient processing of large, whole genome genotype data sets in variant call format including several functions to calculate commonly used population genomic metrics and a method for reference panel free genotype imputation. See Gurke & Mayer (2024) for background and the vignette to get started. \nSuperCell v1.0: Provides tools to aggregate large single-cell data into metacell dataset by merging together gene expression of very similar cells See the vignettes Example of SuperCell pipeline and SuperCell runs for different samples.\n\n\n\n\n\n\n\nLingusitics\nmaxent.ot v1.0.0: Provides tools to fit Maximum Entropy models to phonology data. See Mayer, Tan & Zuraw and the vignette for an overview.\n\n\nMachine Learning\nconversim v0.1.0: Provides tools to analyze and compare conversations using various similarity measures including topic, lexical, semantic, structural, stylistic, sentiment, participant, and timing similarities. Methods are based on established research: For example see Landauer et al. (1998) Jaccard (1912) and Salton & Buckley (1988). Thee are four vignettes including analyzing similarities between two long speaches and analyzing similarities in conversational sequence in one Dyad and across multiple Dyads.\ndsld v0.2.2: Provides statistical and graphical tools for detecting and measuring discrimination and bias, be it racial, gender, age or other. Detection and remediation of bias in machine learning algorithms. See the Quick Start Guide.\n\n\nMedicine\nSurvMA v1.6.8: Implements a model averaging approach to predict personalized survival probabilities by using a weighted average of multiple candidate models to approximate the conditional survival function.Two scenarios of candidate models are allowed: the partial linear Cox model and the time-varying coefficient Cox model. See Wang (2023) for details and look here for an example.\n\n\n\n\n\nwintime v0.2.0: Provides methods to perform an analysis of time-to-event clinical trial data using various methods that calculate and compare treatment effects on ordered composite endpoints. See Troendle et al. (2024) for the details of the methods and the vignette for examples.\n\n\nNetworks\narlclustering v1.0.5: Implements an innovative approach to community detection in social networks using Association Rules Learning providing tools for processing graph and rules objects, generating association rules, and detecting communities based on node interactions. See El-Moussaoui et al. (2021) for details. There are eight vignettes including General Introduction and Testing WordAdjacency dataset.\nggtangle v0.0.2: Extends the ggplot2 plotting system to support network visualization for network associated data. See the vignette.\n\n\n\n\n\n\n\nPharma\nsdtm.oak v0.1.0: Provides a framework to develop CDISC, SDTM datasets in R and potentially automate the process. There are six vignettes including on on Algorithms.\n\n\n\n\n\n\n\nPhysics\nrice v0.3.0: Provides functions to calibrate radiocarbon dates, different radiocarbon realms (C14 age, F14C, pMC, D14C) and to estimate the effects of contamination or local reservoir offsets. See Reimer and Reimer 2001 and Stuiver and Polach (1977) for background and the vignette for examples.\n\n\n\n\n\nSTICr v1.0: Comprises a collection of functions for processing raw data from Stream Temperature, Intermittency, and Conductivity (STIC) loggers. ‘STICr’ (pronounced “sticker”) that includes functions for tidying, calibrating, classifying, and doing quality checks on data from STIC sensors. See Wheeler/Zipper et al. (2023) for background and the vignette for an Introduction.\n\n\n\n\n\n\n\nStatistics\ndpasurv v0.1.0: Provides functions to implement dynamic path analysis for survival data via Aalen’s additive hazards model. See Fosen et al., (2006) for details. There is an oveview and a vignette on plotting with ggplot2.\n\n\n\n\n\nLearnVizLLM v1.0.0: Implements tools to summarize the characteristics of linear fixed models without data or a fitted model by converting code code for fitting nlme::lme() and lme4::lmer() models into tables, equations, and visuals. See the vignette for details.\n\n\n\n\n\nlnmixsurv v3.1.6: Combines the mixture distributions of Fruhwirth-Schnatter(2006) and the data augmentation techniques of Tanner and Wong (1987) to implement Bayesian Survival models that accommodate different behavior over time and consider higher censored survival times. There are five vignettes including a [Get started guide}\nPath.Analysis v0.1: Provides functions for conducting sequential path coefficient analysis and testing direct effects and functions for estimating correlation, drawing correlograms, heatmaps, and path diagrams. See Arminian et al. (2008) for background and the vignette for examples.\n\n\n\n\n\n\n\nUtilities\ncharcuterie v0.0.4: Creates a new chars class which looks like a string but is actually a vector of individual characters, making strings iterable and enabling vector operations on ‘strings’ such as reverse, sort, head, and set operations. See the vignettes Example Usage and Use Cases.\n\n\n\n\n\ndtreg v1.0.0: Provides tools to interact with data type registries and create machine-readable data. See the vinette.\nfctutils v0.0.7: Provides a collection of utility functions for manipulating and analyzing factor vectors in R. It offers tools for filtering, splitting, combining, and reordering factor levels based on various criteria. See the vignette.\ninterface v0.1.2: Provides a run time type system, allowing users to define and implement interfaces, enums, typed data.frame/data.table, as well as typed functions. This package enables stricter type checking and validation, improving code structure, robustness and reliability. There is a vignette and a way to support the author.\npikchrV0.97 : Provides an interface to pikchr q markup language for creating diagrams within technical documentation. See the vignette for examples.\n\n\n\n\n\nrnix v0.12.4: Provides tools to run the nix package manager. There are fifteen vignettes including a Getting Started Gude.\nqs2 v0.1.1: Provides tools to efficiently serialize R objects using one of two compression formats: the qs2 format, which uses R serialization while optimizing compression and disk I/O, and the qdata format which uses custom serialization to achieve slightly faster performance and better compression. qs2 format can be directly converted to the standard RDS. See the vignette\n\n\nVisualization\nggalign v0.0.4: Implements an extension to ggplot2 that offers various tools for organizing and arranging plots including the ability to consistently align a specific axis across multiple ggplot objects. There are seven vignettes including Examples and Heatmap Layout.\n\n\n\n\n\nsfcurv v1.0: Implements all possible forms of 2x2 and 3x3 space-filling curves, i.e., the generalized forms of the Hilbert curve, the Peano curve and the Peano curve in the meander type. Look here for examples.\n\n\n\n\n\nsurreal v0.0.1: Implements the Residual (Sur)Realism algorithm described by Stefanski (2007) to generate datasets that reveal hidden images or messages in their residual plots. See README for examples.\n\n\n\n\n\nsurvSAKK v1.3.1: Provides functions to incorporate various statistics and layout customization options to enhance the efficiency and adaptability of the Kaplan-Meier plots. See the vignette."
  },
  {
    "objectID": "posts/welcome-to-rworks/index.html",
    "href": "posts/welcome-to-rworks/index.html",
    "title": "Welcome to R Works!",
    "section": "",
    "text": "Artwork by @allison_horst\n\n\nThis is a heartfelt welcome to all members of the R community, from long-time readers of R Views to those just joining us. For years, R Views served as a source of resources, insights, and inspiration for R users. We are delighted to bring those ambitions to a new, Quarto-powered technical blog. Our goal is that R Works becomes a hub for news, opinions, and stories as the landscape of R continues to grow and evolve.\nR is more than code, it’s also the people behind it. We hope this blog reflects diverse perspectives and experiences from across the community. To that end, we invite your voices to help shape this space together. If you have unique perspectives, updates, commentary, or examples of using R that you’d love to share, we want to hear from you.\nHappy Reading!"
  },
  {
    "objectID": "posts/august-2024-top-40-new-cran-packages/index.html",
    "href": "posts/august-2024-top-40-new-cran-packages/index.html",
    "title": "August 2024: Top 40 New CRAN Packages",
    "section": "",
    "text": "“Top 40” is back, broadcasting on the new R Works blog. I hope to continue the monthly evaluation of R packages that ran for several years on RStudio’s R Views Blog. The following is an idiosyncratic selection of the forty best new R packages submitted to CRAN in August 2024 organized into fourteen categories: Artificial Intelligence, Computational Methods, Data, Ecology, Environment, Genomics, Machine Learning, Medicine, Pharma, Science, Statistics, Time Series, Utilities, and Visualization.\n\nArtificial Intelligence\ngemini.R v0.5.2: Provides an R interface to Google Gemini API for advanced language processing, text generation, and other AI-driven capabilities within the R environment. See README to get started.\npromptr v1.0.0: Provides functions to form and submit prompts to OpenAI’s Large Language Models. Designed to be particularly useful for text classification problems in the social sciences. See Ornstein, Blasingame, & Truscott (2024) for details and README for an example.\n\n\n\n\n\n\n\nComputational Methods\nqvirus v 0.0.2: Provides code and resources to explore the intersection of quantum computing and artificial intelligence (AI) in the context of analyzing Cluster of Differentiation 4 (CD4) lymphocytes and optimizing antiretroviral therapy (ART) for human immunodeficiency virus (HIV). See the vignettes Introduction, Applications, and Entanglement.\nRcppBessel v1.0.0: Exports an Rcpp interface for the Bessel functions in the ‘Bessel’ package, which can then be called from the C++ code of other packages. For the original ‘Fortran’ implementation of these functions, see Amos (1995). There is a vignette.\n\n\nData\naebdata v0.1.0: Facilitates access to the data from the Atlas do Estado Brasileiro maintained by the Instituto de Pesquisa Econômica Aplicada (Ipea). It allows users to search for specific series, list series, or themes, and download data when available. See the vignette.\ncapesData v0.0.1: Provides information on activities to promote scholarships in Brazil and abroad for international mobility programs recorded in the CAPES database from 2010 to 2019. See README to get started.\n\n\nEcology\npriorCON v0.1.1: Provides a tool set that incorporates graph community detection methods into systematic conservation planning. It is designed to enhance spatial prioritization by focusing on the protection of areas with high ecological connectivity and on clusters of features that exhibit strong ecological linkages. See the Introduction.\n\n\n\n\n\n\n\nEnvironment\nprior3D v0.1.0: Offers a comprehensive toolset for 3D systematic conservation planning, conducting nested prioritization analyses across multiple depth levels and ensuring efficient resource allocation throughout the water column. See Doxa et al. (2022) for background and the vignette for an example.\n\n\n\n\n\nraem v0.1.0: Implements a model of single-layer groundwater flow in steady-state under the Dupuit-Forchheimer assumption can be created by placing elements such as wells, area-sinks, and line-sinks at arbitrary locations in the flow field. See Haitjema (1995) for the underlying theory and the vignettes Overview and Exporting spatial data.\n\n\n\n\n\n\n\nGenomics\nkmeRtone v 1.0: Provides functions for multi-purpose k-meric enrichment analysis, which measures the enrichment of k-mers by comparing the population of k-mers in the case loci with an internal negative control group consisting of k-mers from regions close to, yet sufficiently distant from, the case loci. This method captures both the local sequencing variations and broader sequence influences while also correcting for potential biases. See the GitHub repo for an overview.\nrYWAASB v0.1: Provides a new ranking algorithm to distinguish the top-ranked genotypes. “WAASB” refers to the “Weighted Average of Absolute Scores” provided by Olivoto et al. (2019), which quantifies the stability of genotypes across different environments using linear mixed-effect models. See the vignette for an example.\n\n\n\n\n\n\n\nMachine Learning\ncvLM v1.0.4: Provides efficient implementations of cross-validation techniques for linear and ridge regression models, leveraging C++ code with Rcpp that supports leave-one-out, generalized, and K-fold cross-validation methods. See README for an example.\ngeodl v0.2.0: Provides tools for semantic segmentation of geospatial data using convolutional neural network-based deep learning, including utility functions for manipulating data, model checks, functions to implement a UNet architecture with four blocks in the encoder, assessment metrics, and more. The package relies on torch but does not require installing a Python environment. Models can be trained using a Compute Unified Device Architecture (CUDA)-enabled graphics processing unit (GPU). There are ten vignettes, including spatialPredictionDemo and topoDLDemo.\n\n\n\n\n\nidiolect v1.0.1: Provides functions for the comparative authorship analysis of disputed and undisputed texts within the Likelihood Ratio Framework for expressing evidence in forensic science and implements well-known algorithms, including Smith and Aldridge’s (2011) Cosine Delta and Koppel and Winter’s (2014) Impostors Method. See the vignette.\n\n\n\n\n\nkdml v1.0.0: Implements distance metrics for mixed-type data consisting of continuous, nominal, and ordinal variables, which can be used in any distance-based algorithm, such as distance-based clustering. See Ghashti and Thompson (2024) for dkps() methodology, Ghashti (2024) for dkss() methodology, and the vignette.\nkerntools v1.0.2: Provides kernel functions for diverse types of data including, but not restricted to: non-negative and real vectors, real matrices, categorical and ordinal variables, sets, strings, plus other utilities like kernel similarity, kernel Principal Components Analysis (PCA) and features’ importance for Support Vector Machines (SVMs). See the vignette.\n\n\n\nScatter plot for Drac kernal PCA\n\n\nMorphoRegions v0.1.0: Provides functions to computationally identify regions in serially homologous structures such as, but not limited to, the vertebrate backbone. Regions are modeled as segmented linear regressions, with each segment corresponding to a region and region boundaries (or breakpoints) corresponding to changes along the serially homologous structure.\n\n\n\n\n\n\n\nMedicine\nneuroUP v0.3.1: Provides functions to calculate the precision in mean differences (raw or Cohen’s D) and correlation coefficients for different sample sizes using permutations of the collected functional magnetic resonance imaging (fMRI) data. See Klapwijk et al. (2024) for background and the vignette for an introduction.\n\n\n\n\n\nsmiles v0.1-0: Provides tools aimed at making data synthesis and evidence evaluation easier for both experienced practitioners and newcomers. See the Cochrane Handbook for Systematic Reviews of Interventions and the vignette for examples.\n\n\n\n\n\ntsgc v0.0: Provides tools to analyze and forecast epidemic trajectories based on a dynamic Gompertz model and a state space approach that uses the Kalman filter for robust estimation of the non-linear growth pattern commonly observed in epidemic data. See Harvey and Kattuman (2020), Harvey and Kattuman (2021), and Ashby et al. (2024) for background and the vignette for details.\n\n\n\n\n\n\n\nPharma\nadmiralpeds v0.1.0: Provides a toolbox for programming Clinical Data Standards Interchange Consortium (CDISC) compliant Analysis Data Model (ADaM) data sets in R. See the vignette for an example.\nMALDIcellassay v0.4.47: Implements tools to conduct automated cell-based assays using Matrix-Assisted Laser Desorption/Ionization (MALDI) methods for high-throughput screening of signals responsive to treatments. The methodologies were introduced by Weigt et al. (2018) and Unger et al. (2021). See the vignette for an example.\n\n\n\n\n\n\n\nScience\nbarrks v1.0.0: Implements models to calculate the bark beetle phenology and their submodels, onset of infestation, beetle development, diapause initiation, and mortality, which can be customized and combined. Models include PHENIPS-Clim, PHENIPS, RITY, CHAPY, and BSO. There are five vignettes, including The BSO model and Example: Model Comparison.\n\n\n\n\n\nfluxible v0.0.1: Provides functions to process the raw data from closed loop flux chamber (or tent) setups into ecosystem gas fluxes usable for analysis. Implemented models include exponential Zhao et al. (2018) and quadratic and linear models to estimate the fluxes from the raw data. See the vignette for an example.\n\n\nStatistics\nbage v0.7.4: Provides functions for Bayesian estimation and forecasting of age-specific rates, probabilities, and means based on the Template Model Builder. There are six vignettes, including the Mathematical Details and an Example.\n\n\n\n\n\nclustMC v0.1.1: Implements cluster-based multiple comparisons tests and also provides a visual representation in the form of a dendrogram. See Rienzo, Guzmán & Casanoves (2002) and Bautista, Smith & Steiner (1997), and the vignette for examples.\n\n\n\n\n\nsvycdiff v0.1.1: Provides three methods for estimating the population average controlled difference for a given outcome between levels of a binary treatment, exposure, or other group membership variables of interest for clustered, stratified survey samples where sample selection depends on the comparison group. See Salerno et al. (2024) for background and the vignette for an example.\nwishmom v1.1.0: Provides functions for computing moments and coefficients related to the Beta-Wishart and Inverse Beta-Wishart distributions, including functions for calculating the expectation of matrix-valued functions of the Beta-Wishart distribution, coefficient matrices, and expectation of matrix-valued functions of the inverse Beta-Wishart distribution. See the vignette for details.\n\n\nTime Series\ntican v1.0.1: Provides functions to analyze and plot time-intensity curves such as those that arise from contrast-enhanced ultrasound images. See the vignette.\ntidychangepoint v0.0.1: Provides a tidy, unified interface for several different changepoint detection algorithms, along with a consistent numerical and graphical reporting leveraging the broom and ggplot2 packages. See the vignette.\n\n\n\n\n\n\n\nUtilities\nfio v0.1.2: Provides tools to simplify the process of importing and managing input-output matrices from Microsoft Excel into R. It leverages the R6 class for memory-efficient object-oriented programming implements all linear algebra computations in Rust. See the vignette.\nlitedown v0.2: Implements a lightweight version of R Markdown, which enables rendering R Markdown to Markdown without using knitr, and Markdown to lightweight HTML/LaTeX documents using the commonmark package instead of Pandoc. This package can be viewed as a trimmed-down version of R Markdown and knitr, which does not aim at rich Markdown features or a large variety of output formats. There are vignettes on Markdown Examples, HTML Output Examples, and Making HTMLSlides.\nmaestro v0.2.0: Implements a framework for creating and orchestrating data pipelines allowing users to organize, orchestrate, and monitor multiple pipelines in a single project. There are four vignettes, including a Quick Start Guide and Use Cases.\nosum v0.1.0: Inspired by S-PLUS function objects.summary(), provides a function that returns data class, storage mode, mode, type, dimension, and size information for R objects in the specified environment. Various filtering and sorting options are also proposed. See the vignette.\novertureR v0.2.3: Implements n integrated R interface to the Overture’ API which allows R users to return Overture data as dbplyr data frames or materialized sf spatial data frames. See README for examples.\n\n\n\n\n\nRcppMagicEnum v0.0.1: Provides Rcpp bindings to header-only modern C++ template library Magic Enum. See README to get started.\n\n\n\n\n\ntidymodelr v1.0.0: Provides a function to transform long data into a matrix form to allow for ease of input into modeling packages for regression, principal components, imputation, or machine learning along with level analysis wrapper functions for correlation and principal components analysis. See README for examples.\n\n\nVisualization\nbullseye v0.1.0: Provides a tidy data structure and visualizations for multiple or grouped variable correlations, general association measures, diagnostics, and other pairwise scores suitable for numerical, ordinal, and nominal variables. Supported measures include distance correlation, maximal information, ace correlation, Kendall’s tau, and polychoric correlation. There are three vignettes including Calculating Pairwise Scores and Visualizing Pairwise Scores.\n\n\n\n\n\nflowmapper v0.1.2: Adds flow maps to ggplot2 plots. These are layers that visualize the nodes as circles and the bilateral flows between the nodes as bidirectional half-arrows. Look here for details and examples.\n\n\n\n\n\nggreveal v0.1.3: Provides functions that make it easy to reveal ggplot2 graphs incrementally. The functions take a plot produced with ggplot2 and return a list of plots showing data incrementally by panels, layers, groups, the values in an axis, or any arbitrary aesthetic. See the GitHub repo for examples."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to R Works.\nR Works is the blog devoted to the R community and the R language. We imagine it as a place to read considered opinions about topics of interest to the R community, learn what is happening at conferences and user group meetings around the world, discover new R packages, and explore applications of R in various areas of statistics or data science.\nR Works is powered by Quarto. We moved to this platform to provide an enhanced experience for our readers. With Quarto’s advanced features, we can showcase R-related topics and deliver high-quality content.\nThe blog is edited by Joseph Rickert and Isabella Velásquez, who curate the content and ensure its quality. We hope that R Works will continue to attract other voices from around the R community. If you have something to say on an R-related topic, news, commentary, or an example of using R that you would like to share with the R community, please review the How to page."
  }
]